{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity-Based Movie Recommendation System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting up the Data\n",
    "\n",
    "This dataset is a series of reviews and ratings of movies from Grouplens.org. \n",
    "https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is divided into two files. File 1 contain rating, movie_id and File 2 contain movie_id, title.\n",
    "So concatinating both the file in one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/dhruvil/Downloads/ml-latest-small/ml-latest-small/ratings.tsv'\n",
    "path1='/Users/dhruvil/Downloads/ml-latest-small/ml-latest-small/movies.tsv'\n",
    "\n",
    "f = open(path, 'rt', encoding=\"utf8\")\n",
    "f1 = open(path1, 'rt', encoding=\"utf8\")\n",
    "\n",
    "\n",
    "\n",
    "header = f.readline()\n",
    "header = header.strip().split('\\t')\n",
    "header[0] = header[0][1:]\n",
    "\n",
    "header1 = f1.readline()\n",
    "header1 = header1.strip().split('\\t')\n",
    "header1[0] = header1[0][1:]\n",
    "data1=[]\n",
    "for line1 in f1:\n",
    "    fields1 = line1.strip().split('\\t')\n",
    "    d1 = dict(zip(header1, fields1))\n",
    "    data1.append(d1)\n",
    "\n",
    "#print(data1)\n",
    "\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for line in f:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    \n",
    "    for x in data1:\n",
    "    #    fields1 = line1.strip().split('\\t')\n",
    "    #    d1 = dict(zip(header1, fields1))\n",
    "    #    print(d['movieId'],d1['movieId'])\n",
    "        if d['movieId']==x['movieId']:\n",
    "            d['timestamp'] = x['title']\n",
    "        \n",
    "        \n",
    "    d['rating'] = float(d['rating'])\n",
    "    dataset.append(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what a typical entry will look like in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId movieId  rating                       timestamp\n",
      "0           1       1     4.0                Toy Story (1995)\n",
      "1           1       3     4.0         Grumpier Old Men (1995)\n",
      "2           1       6     4.0                     Heat (1995)\n",
      "3           1      47     5.0     Seven (a.k.a. Se7en) (1995)\n",
      "4           1      50     5.0      Usual Suspects, The (1995)\n",
      "...       ...     ...     ...                             ...\n",
      "100831    610  166534     4.0                    Split (2017)\n",
      "100832    610  168248     5.0   John Wick: Chapter Two (2017)\n",
      "100833    610  168250     5.0                  Get Out (2017)\n",
      "100834    610  168252     5.0                    Logan (2017)\n",
      "100835    610  170875     3.0  The Fate of the Furious (2017)\n",
      "\n",
      "[100836 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Finding Similarities\n",
    "\n",
    "Here we determmine ratings given by each user to multiple movies. So inorder to find the average rating a particular gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "\n",
    "itemNames = {}\n",
    "\n",
    "for d in dataset:\n",
    "    user,item = d['userId'], d['movieId']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    itemNames[item] = d['timestamp']\n",
    "#print(itemsPerUser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to find Similarities\n",
    "\n",
    "We need to set up our Jaccard function and a function to determine what is similar within the dataset. Instead of Jaccard Function you can also use cosine function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(iD, n):\n",
    "    similarities = []\n",
    "    id_list = []\n",
    "    users = usersPerItem[iD]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == iD: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append((sim,i2))\n",
    "        \n",
    "    similarities.sort(reverse=True)\n",
    "    \n",
    "    for i in similarities:\n",
    "        id_list.append(i[1])\n",
    "        \n",
    "    print(id_list[:n])\n",
    "    return similarities[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a recommendation\n",
    "\n",
    "In this section we will get prediction for any particular user based on his ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': '1', 'movieId': '6', 'rating': 4.0, 'timestamp': 'Heat (1995)'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'163'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = dataset[10]['movieId']\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Desperado (1995)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemNames[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['353', '555', '6', '380', '173', '288', '293', '553', '552', '16']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.3, '353'),\n",
       " (0.297029702970297, '555'),\n",
       " (0.2923076923076923, '6'),\n",
       " (0.26424870466321243, '380'),\n",
       " (0.2549019607843137, '173'),\n",
       " (0.25396825396825395, '288'),\n",
       " (0.25157232704402516, '293'),\n",
       " (0.24761904761904763, '553'),\n",
       " (0.24509803921568626, '552'),\n",
       " (0.24369747899159663, '16')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilar(query, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['353', '555', '6', '380', '173', '288', '293', '553', '552', '16']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Crow, The (1994)',\n",
       " 'True Romance (1993)',\n",
       " 'Heat (1995)',\n",
       " 'True Lies (1994)',\n",
       " 'Judge Dredd (1995)',\n",
       " 'Natural Born Killers (1994)',\n",
       " 'Léon: The Professional (a.k.a. The Professional) (Léon) (1994)',\n",
       " 'Tombstone (1993)',\n",
       " 'Three Musketeers, The (1993)',\n",
       " 'Casino (1995)']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Top 10 recommended movies for the user....\n",
    "\n",
    "[itemNames[x[1]] for x in mostSimilar(query, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Collaborative-Filtering-Based Rating Estimation\n",
    "\n",
    "We can also use the similarity-based recommender we developed above to make predictions about user's ratings.\n",
    "\n",
    "Specifically, a user's rating for an item is assumed to be a weighted sum of their previous ratings, weighted by how similar the query item is to each of their previous purchases.\n",
    "\n",
    "We start by building a few more utility data structures to keep track of all of the reviews by each user and for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "c=0\n",
    "for d in dataset:\n",
    "    user,item = d['userId'], d['movieId']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.501556983616962\n"
     ]
    }
   ],
   "source": [
    "#Calculating the mean rating of the entire dataset\n",
    "\n",
    "total_star_rating = 0\n",
    "c1=0\n",
    "for d in dataset:\n",
    "    total_star_rating += d['rating']\n",
    "    c1=c1+1\n",
    "avg_star_rating = total_star_rating/c1\n",
    "print(avg_star_rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated the average rating of our dataset as a whole, we are going to implement a function which predicts Rating based on a user and an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['movieId']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return avg_star_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': '1',\n",
       " 'movieId': '163',\n",
       " 'rating': 5.0,\n",
       " 'timestamp': 'Desperado (1995)'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.357645946451583"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting rating for the user at index [10]\n",
    "\n",
    "user,item = dataset[10]['userId'], dataset[10]['movieId']\n",
    "predictRating(user, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case our user hasn't rated any similar items, so our function defaults to returning the dataset Mean Rating. Let's try another example with a user who has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.394928680387841"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting rating for the user at index [12]\n",
    "user,item = dataset[12]['userId'], dataset[12]['movieId']\n",
    "predictRating(user, item)\n",
    "#Answer should differ from the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluating Performance\n",
    "\n",
    "Lets start by defining out typical MSE function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of our model, we will need two things:\n",
    "1. A list of the average Rating (i.e. ratingMean)\n",
    "2. A list of our predicted ratings (i.e. ratings defined by our predictRating function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingMean = []\n",
    "predictedRatinng = []\n",
    "for d in range(10):\n",
    "    ratingMean.append(avg_star_rating)\n",
    "    \n",
    "    user,item = dataset[d]['userId'], dataset[d]['movieId']\n",
    "    predictedRatinng.append(predictRating(user, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will compare our two lists above with the actual star ratings in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.247199853687452 0.4462077996374793\n"
     ]
    }
   ],
   "source": [
    "labels = [d['rating'] for d in dataset]\n",
    "print(MSE(ratingMean, labels), MSE(predictedRatinng, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
